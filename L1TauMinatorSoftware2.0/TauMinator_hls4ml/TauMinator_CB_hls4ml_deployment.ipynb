{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f2ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/llr/cms/motta/.local/lib/python3.9/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotting\n",
    "import hls4ml\n",
    "import shap\n",
    "import sys\n",
    "import os\n",
    "\n",
    "np.random.seed(77)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep\n",
    "plt.style.use(mplhep.style.CMS)\n",
    "\n",
    "\n",
    "def print_dict(d, indent=0):\n",
    "    align=20\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key), end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent+1)\n",
    "        else:\n",
    "            print(':' + ' ' * (20 - len(key) - 2 * indent) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /data/elec_soft/Xilinx_Software/Soft_2020.1/Vivado/2020.1/settings64.sh: No such file or directory\n",
      "/bin/bash: /data/elec_soft/Xilinx_Software/Soft_2020.1/Vitis/2020.1/settings64.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "os.environ['PATH'] = '/data/elec_soft/Xilinx_Software/Soft_2020.1/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "!source /data/elec_soft/Xilinx_Software/Soft_2020.1/Vivado/2020.1/settings64.sh\n",
    "os.environ['PATH'] = '/data/elec_soft/Xilinx_Software/Soft_2020.1/Vitis/2020.1/bin:' + os.environ['PATH']\n",
    "!source /data/elec_soft/Xilinx_Software/Soft_2020.1/Vitis/2020.1/settings64.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99815228",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'v'          : '16',\n",
    "    'date'       : '2023_05_28',\n",
    "    'inTagIdent' : '_QP',\n",
    "    'inTagCalib' : '_QP',\n",
    "    'caloClNxM'  : '5x9',\n",
    "    'sparsity'   : 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2629d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '/data_CMS/cms/motta/Phase2L1T/'+options['date']+'_v'+options['v']+'/TauMinator_CB_cltw'+options['caloClNxM']+'_Training'+options['inTagIdent']\n",
    "\n",
    "N = int(options['caloClNxM'].split('x')[0])\n",
    "M = int(options['caloClNxM'].split('x')[1])\n",
    "\n",
    "sparsityTag = str(options['sparsity']).split('.')[0]+'p'+str(options['sparsity']).split('.')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10a441",
   "metadata": {},
   "source": [
    "**Only models with one input tensor are currently supported by VivadoAcceleratorBackend.\n",
    "Therefore, the CNN model is in this case a special version that takes only the image as an input and gives as an output the flattened tensor out of the convolutions withou concatenating the position of the cluster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0c07a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 14:09:17.315853: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /grid_mnt/opt__exp_soft/llr/python/3.9.9/lib/python3.9/site-packages/cv2/../../lib64:/opt/exp_soft/llr/python/3.9.9/lib/vtk:/opt/exp_soft/llr/python/3.9.9/lib:/usr/lib64/classads:/usr/lib64:/usr/lib\n",
      "2023-07-04 14:09:17.315897: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-04 14:09:17.316312: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# quantized and pruned models\n",
    "QCNN = keras.models.load_model(indir+'/CNNmodel_special4accelerator', compile=False)\n",
    "QDNNident = keras.models.load_model(indir+'/ID_DNNmodel', compile=False)\n",
    "QDNNcalib = keras.models.load_model(indir+'/CAL_DNNmodel', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197733f6",
   "metadata": {},
   "source": [
    "# QUANTIZED MODELS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc8f574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: TowerClusterImage, layer type: Input\n",
      "Layer name: CNNpBNlayer1, layer type: QConv2DBatchnorm\n",
      "  -> Activation (linear), layer name: CNNpBNlayer1\n",
      "Layer name: RELU_CNNpBNlayer1, layer type: QActivation\n",
      "  -> Activation (quantized_relu(10,7)), layer name: RELU_CNNpBNlayer1\n",
      "Layer name: MP_CNNpBNlayer1, layer type: MaxPooling2D\n",
      "Layer name: CNNpBNlayer2, layer type: QConv2DBatchnorm\n",
      "  -> Activation (linear), layer name: CNNpBNlayer2\n",
      "Layer name: RELU_CNNpBNlayer2, layer type: QActivation\n",
      "  -> Activation (quantized_relu(9,6)), layer name: RELU_CNNpBNlayer2\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'TowerClusterImage': {'Precision': 'ap_ufixed<10,8>', 'Strategy': 'Latency', 'ReuseFactor': 1, 'Trace': True}, 'CNNpBNlayer1': {'Precision': {'weight': 'ap_fixed<5,1>', 'bias': 'ap_fixed<6,1>', 'accum': 'ap_fixed<14,7>', 'result': 'ap_fixed<14,7>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'Trace': True, 'ParallelizationFactor': 4}, 'CNNpBNlayer1_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Latency', 'Trace': True}, 'RELU_CNNpBNlayer1': {'Precision': {'result': 'ap_fixed<10,7>', 'accum': 'ap_fixed<10,7>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'Trace': True}, 'RELU_CNNpBNlayer1_quantized_relu(10,7)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Latency', 'Trace': True}, 'MP_CNNpBNlayer1': {'Precision': 'ap_fixed<10,7>', 'Strategy': 'Latency', 'ReuseFactor': 1, 'Trace': True}, 'CNNpBNlayer2': {'Precision': {'weight': 'ap_fixed<5,1>', 'bias': 'ap_fixed<6,1>', 'accum': 'ap_fixed<14,6>', 'result': 'ap_fixed<14,6>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'Trace': True}, 'CNNpBNlayer2_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Latency', 'Trace': True}, 'RELU_CNNpBNlayer2': {'Precision': {'result': 'ap_fixed<9,6>', 'accum': 'ap_fixed<9,6>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'Trace': True}, 'RELU_CNNpBNlayer2_quantized_relu(9,6)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Latency', 'Trace': True}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: TowerClusterImage, layer type: InputLayer, input shapes: [[None, 5, 9, 3]], output shape: [None, 5, 9, 3]\n",
      "Layer name: CNNpBNlayer1, layer type: QConv2DBatchnorm, input shapes: [[None, 5, 9, 3]], output shape: [None, 4, 8, 4]\n",
      "Layer name: RELU_CNNpBNlayer1, layer type: Activation, input shapes: [[None, 4, 8, 4]], output shape: [None, 4, 8, 4]\n",
      "Layer name: MP_CNNpBNlayer1, layer type: MaxPooling2D, input shapes: [[None, 4, 8, 4]], output shape: [None, 2, 4, 4]\n",
      "Layer name: CNNpBNlayer2, layer type: QConv2DBatchnorm, input shapes: [[None, 2, 4, 4]], output shape: [None, 1, 3, 8]\n",
      "Layer name: RELU_CNNpBNlayer2, layer type: Activation, input shapes: [[None, 1, 3, 8]], output shape: [None, 1, 3, 8]\n",
      "Layer name: CNNflattened, layer type: Reshape, input shapes: [[None, 1, 3, 8]], output shape: [None, 24]\n",
      "Creating HLS model\n",
      "WARNING: Cannot use \"Latency\" model strategy for {} layer. Switching to \"Resource\" strategy.\n",
      "WARNING: Final layer is a Reshape, which does not affect the output for io_parallel; removing it\n",
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "############################## Pass quantized CNN model through hls4ml ##############################\n",
    "\n",
    "compl = True\n",
    "synth = False\n",
    "if compl:\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'],\n",
    "                                                                                      rounding_mode='AP_RND',\n",
    "                                                                                      saturation_mode='AP_SAT')\n",
    "\n",
    "    # baseline model\n",
    "    QCNN_hls_cfg = hls4ml.utils.config_from_keras_model(QCNN, granularity='name')\n",
    "    QCNN_hls_cfg['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "    QCNN_hls_cfg['Model']['ReuseFactor'] = 1\n",
    "    for Layer in QCNN_hls_cfg['LayerName'].keys():\n",
    "        QCNN_hls_cfg['LayerName'][Layer]['Strategy'] = 'Latency'\n",
    "        QCNN_hls_cfg['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        QCNN_hls_cfg['LayerName'][Layer]['Trace'] = True\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['TowerClusterImage']['Precision'] = 'ap_ufixed<10,8>'\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer1']['ParallelizationFactor'] = 4\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer1']['Precision']['weight'] = 'ap_fixed<5,1>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer1']['Precision']['bias'] = 'ap_fixed<6,1>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer1']['Precision']['accum'] = 'ap_fixed<14,7>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer1']['Precision']['result'] = 'ap_fixed<14,7>'\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['RELU_CNNpBNlayer1']['Precision']['accum'] = 'ap_fixed<10,7>'\n",
    "    QCNN_hls_cfg['LayerName']['RELU_CNNpBNlayer1']['Precision']['result'] = 'ap_fixed<10,7>'\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['MP_CNNpBNlayer1']['Precision'] = 'ap_fixed<10,7>'\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer2']['Precision']['weight'] = 'ap_fixed<5,1>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer2']['Precision']['bias'] = 'ap_fixed<6,1>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer2']['Precision']['accum'] = 'ap_fixed<14,6>'\n",
    "    QCNN_hls_cfg['LayerName']['CNNpBNlayer2']['Precision']['result'] = 'ap_fixed<14,6>'\n",
    "\n",
    "    QCNN_hls_cfg['LayerName']['RELU_CNNpBNlayer2']['Precision']['result'] = 'ap_fixed<9,6>'\n",
    "    QCNN_hls_cfg['LayerName']['RELU_CNNpBNlayer2']['Precision']['accum'] = 'ap_fixed<9,6>'\n",
    "\n",
    "    print(QCNN_hls_cfg)\n",
    "\n",
    "    QCNN_hls = hls4ml.converters.convert_from_keras_model(QCNN,\n",
    "                                                          hls_config=QCNN_hls_cfg,\n",
    "                                                          output_dir=indir+'/CNNmodel_HLS_XCU200deployment/',\n",
    "                                                          backend='VivadoAccelerator',\n",
    "                                                          board='alveo-u200',\n",
    "                                                          io_type='io_parallel',\n",
    "                                                          platform='xilinx_u200_xdma_201830_2')\n",
    "\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=[])\n",
    "    QCNN_hls.compile()\n",
    "\n",
    "if synth:\n",
    "    QCNN_hls.build(csim=False, synth=True, vsynth=True, export=True, bitfile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10e02c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: middleMan, layer type: Input\n",
      "Layer name: IDlayer1, layer type: QDense\n",
      "  -> Activation (linear), layer name: IDlayer1\n",
      "Layer name: RELU_IDlayer1, layer type: QActivation\n",
      "  -> Activation (quantized_relu(9,6)), layer name: RELU_IDlayer1\n",
      "Layer name: IDlayer2, layer type: QDense\n",
      "  -> Activation (linear), layer name: IDlayer2\n",
      "Layer name: RELU_IDlayer2, layer type: QActivation\n",
      "  -> Activation (quantized_relu(8,5)), layer name: RELU_IDlayer2\n",
      "Layer name: IDout, layer type: QDense\n",
      "  -> Activation (linear), layer name: IDout\n",
      "Layer name: sigmoid_IDout, layer type: Activation\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'middleMan': {'Precision': 'ap_fixed<11,6>', 'Strategy': 'Resources', 'ReuseFactor': 1, 'Trace': True}, 'IDlayer1': {'Precision': {'weight': 'ap_fixed<3,1>', 'accum': 'ap_fixed<13,6>', 'result': 'ap_fixed<9,7>'}, 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'IDlayer1_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'RELU_IDlayer1': {'Precision': 'ap_fixed<9,5>', 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'RELU_IDlayer1_quantized_relu(9,6)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'IDlayer2': {'Precision': {'weight': 'ap_fixed<3,1>', 'accum': 'ap_fixed<11,6>', 'result': 'ap_fixed<10,5>'}, 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'IDlayer2_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'RELU_IDlayer2': {'Precision': 'ap_fixed<9,5>', 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'RELU_IDlayer2_quantized_relu(8,5)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'IDout': {'Precision': {'weight': 'ap_fixed<2,1>', 'accum': 'ap_fixed<7,4>', 'result': 'ap_fixed<7,4>'}, 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'IDout_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'sigmoid_IDout': {'Precision': 'ap_fixed<8,1>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Stable', 'Trace': True}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: middleMan, layer type: InputLayer, input shapes: [[None, 26]], output shape: [None, 26]\n",
      "Layer name: IDlayer1, layer type: QDense, input shapes: [[None, 26]], output shape: [None, 16]\n",
      "Layer name: RELU_IDlayer1, layer type: Activation, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: IDlayer2, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 8]\n",
      "Layer name: RELU_IDlayer2, layer type: Activation, input shapes: [[None, 8]], output shape: [None, 8]\n",
      "Layer name: IDout, layer type: QDense, input shapes: [[None, 8]], output shape: [None, 1]\n",
      "Layer name: sigmoid_IDout, layer type: Activation, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "############################## Pass quantized identification DNN model through hls4ml ##############################\n",
    "\n",
    "compl = True\n",
    "synth = False\n",
    "if compl:\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'],\n",
    "                                                                                      rounding_mode='AP_RND',\n",
    "                                                                                      saturation_mode='AP_SAT')\n",
    "\n",
    "    # baseline model\n",
    "    id_QDNN_hls_cfg = hls4ml.utils.config_from_keras_model(QDNNident, granularity='name')\n",
    "    id_QDNN_hls_cfg['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "    id_QDNN_hls_cfg['Model']['ReuseFactor'] = 1\n",
    "    for Layer in id_QDNN_hls_cfg['LayerName'].keys():\n",
    "        id_QDNN_hls_cfg['LayerName'][Layer]['Strategy'] = 'Resources'\n",
    "        id_QDNN_hls_cfg['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        id_QDNN_hls_cfg['LayerName'][Layer]['Trace'] = True\n",
    "\n",
    "    id_QDNN_hls_cfg['LayerName']['middleMan']['Precision'] = 'ap_fixed<11,6>'\n",
    "\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer1']['Precision']['weight'] = 'ap_fixed<3,1>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer1']['Precision']['accum'] = 'ap_fixed<13,6>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer1']['Precision']['result'] = 'ap_fixed<9,7>'\n",
    "    id_QDNN_hls_cfg['LayerName']['RELU_IDlayer1']['Precision'] = 'ap_fixed<9,5>'\n",
    "\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer2']['Precision']['weight'] = 'ap_fixed<3,1>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer2']['Precision']['accum'] = 'ap_fixed<11,6>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDlayer2']['Precision']['result'] = 'ap_fixed<10,5>'\n",
    "    id_QDNN_hls_cfg['LayerName']['RELU_IDlayer2']['Precision'] = 'ap_fixed<9,5>'\n",
    "\n",
    "    id_QDNN_hls_cfg['LayerName']['IDout']['Precision']['weight'] = 'ap_fixed<2,1>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDout']['Precision']['accum'] = 'ap_fixed<7,4>'\n",
    "    id_QDNN_hls_cfg['LayerName']['IDout']['Precision']['result'] = 'ap_fixed<7,4>'\n",
    "\n",
    "    id_QDNN_hls_cfg['LayerName']['sigmoid_IDout']['Precision'] = 'ap_fixed<8,1>'\n",
    "    id_QDNN_hls_cfg['LayerName']['sigmoid_IDout']['Strategy'] = 'Stable'\n",
    "\n",
    "    print(id_QDNN_hls_cfg)\n",
    "\n",
    "    QDNNident_hls = hls4ml.converters.convert_from_keras_model(QDNNident,\n",
    "                                                               hls_config=id_QDNN_hls_cfg,\n",
    "                                                               output_dir=indir+'/ID_DNNmodel_HLS_XCU200deployment/',\n",
    "                                                               backend='VivadoAccelerator',\n",
    "                                                               board='alveo-u200',\n",
    "                                                               io_type='io_parallel',\n",
    "                                                               platform='xilinx_u200_xdma_201830_2')\n",
    "\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=[])\n",
    "    QDNNident_hls.compile()\n",
    "\n",
    "if synth:\n",
    "    QDNNident_hls.build(csim=False, synth=True, vsynth=True, export=True, bitfile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601ed8cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: middleMan, layer type: Input\n",
      "Layer name: CALlayer1, layer type: QDense\n",
      "  -> Activation (linear), layer name: CALlayer1\n",
      "Layer name: RELU_CALlayer1, layer type: QActivation\n",
      "  -> Activation (quantized_relu(9,6)), layer name: RELU_CALlayer1\n",
      "Layer name: CALlayer2, layer type: QDense\n",
      "  -> Activation (linear), layer name: CALlayer2\n",
      "Layer name: RELU_CALlayer2, layer type: QActivation\n",
      "  -> Activation (quantized_relu(9,6)), layer name: RELU_CALlayer2\n",
      "Layer name: CALout, layer type: QDense\n",
      "  -> Activation (linear), layer name: CALout\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Latency'}, 'LayerName': {'middleMan': {'Precision': 'ap_fixed<11,6>', 'Strategy': 'Resources', 'ReuseFactor': 1, 'Trace': True}, 'CALlayer1': {'Precision': {'weight': 'ap_fixed<6,1>', 'accum': 'ap_fixed<16,5>', 'result': 'ap_fixed<16,7>'}, 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'CALlayer1_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'RELU_CALlayer1': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'RELU_CALlayer1_quantized_relu(9,6)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'CALlayer2': {'Precision': {'weight': 'ap_fixed<3,1>', 'accum': 'ap_fixed<16,7>', 'result': 'ap_fixed<12,8>'}, 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'CALlayer2_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'RELU_CALlayer2': {'Precision': 'ap_fixed<10,7>', 'ReuseFactor': 1, 'Strategy': 'Resources', 'Trace': True}, 'RELU_CALlayer2_quantized_relu(9,6)': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}, 'CALout': {'Precision': {'weight': 'ap_fixed<2,1>', 'accum': 'ap_fixed<12,9>', 'result': 'ap_fixed<10,9>'}, 'ReuseFactor': 1, 'Strategy': 'Stable', 'Trace': True}, 'CALout_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resources', 'Trace': True}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: middleMan, layer type: InputLayer, input shapes: [[None, 26]], output shape: [None, 26]\n",
      "Layer name: CALlayer1, layer type: QDense, input shapes: [[None, 26]], output shape: [None, 16]\n",
      "Layer name: RELU_CALlayer1, layer type: Activation, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: CALlayer2, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 8]\n",
      "Layer name: RELU_CALlayer2, layer type: Activation, input shapes: [[None, 8]], output shape: [None, 8]\n",
      "Layer name: CALout, layer type: QDense, input shapes: [[None, 8]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "############################## Pass quantized calibration DNN model through hls4ml ##############################\n",
    "\n",
    "compl = True\n",
    "synth = False\n",
    "if compl:\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'],\n",
    "                                                                                      rounding_mode='AP_RND',\n",
    "                                                                                      saturation_mode='AP_SAT')\n",
    "\n",
    "    # baseline model\n",
    "    cal_QDNN_hls_cfg = hls4ml.utils.config_from_keras_model(QDNNcalib, granularity='name')\n",
    "    cal_QDNN_hls_cfg['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "    cal_QDNN_hls_cfg['Model']['ReuseFactor'] = 1\n",
    "    for Layer in cal_QDNN_hls_cfg['LayerName'].keys():\n",
    "        cal_QDNN_hls_cfg['LayerName'][Layer]['Strategy'] = 'Resources'\n",
    "        cal_QDNN_hls_cfg['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        cal_QDNN_hls_cfg['LayerName'][Layer]['Trace'] = True\n",
    "\n",
    "    cal_QDNN_hls_cfg['LayerName']['middleMan']['Precision'] = 'ap_fixed<11,6>'\n",
    "\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer1']['Precision']['weight'] = 'ap_fixed<6,1>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer1']['Precision']['accum'] = 'ap_fixed<16,5>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer1']['Precision']['result'] = 'ap_fixed<16,7>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['RELU_CALlayer1']['Precision'] = 'ap_fixed<11,7>'\n",
    "\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer2']['Precision']['weight'] = 'ap_fixed<3,1>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer2']['Precision']['accum'] = 'ap_fixed<16,7>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALlayer2']['Precision']['result'] = 'ap_fixed<12,8>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['RELU_CALlayer2']['Precision'] = 'ap_fixed<10,7>'\n",
    "\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALout']['Precision']['weight'] = 'ap_fixed<2,1>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALout']['Precision']['accum'] = 'ap_fixed<12,9>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALout']['Precision']['result'] = 'ap_fixed<10,9>'\n",
    "    cal_QDNN_hls_cfg['LayerName']['CALout']['Strategy'] = 'Stable'\n",
    "\n",
    "    print(cal_QDNN_hls_cfg)\n",
    "\n",
    "    QDNNcalib_hls = hls4ml.converters.convert_from_keras_model(QDNNcalib,\n",
    "                                                               hls_config=cal_QDNN_hls_cfg,\n",
    "                                                               output_dir=indir+'/CAL_DNNmodel_HLS_XCU200deployment/',\n",
    "                                                               backend='VivadoAccelerator',\n",
    "                                                               board='alveo-u200',\n",
    "                                                               io_type='io_parallel',\n",
    "                                                               platform='xilinx_u200_xdma_201830_2')\n",
    "\n",
    "    hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=[])\n",
    "    QDNNcalib_hls.compile()\n",
    "\n",
    "if synth:\n",
    "    QDNNcalib_hls.build(csim=False, synth=True, vsynth=True, export=True, bitfile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe65df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8dc0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/data_CMS/cms/motta/Phase2L1T/2023_05_24_v15/TauMinator_CB_cltw5x9_Training/tensors_AlveoTest/'\n",
    "X1 = np.load(directory+'/images_train.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5e0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfb2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_pred = QCNN_hls.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921c0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "pynqbuffer = np.array([[5.25 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.625, 2.125,\n",
    "             0.   , 0.   , 3.75 , 0.   , 0.   , 0.625, 2.5  , 2.   ,\n",
    "             0.   , 0.   , 1.   , 0.   , 0.875, 1.25 , 0.   , 1.375],\n",
    "            [5.375, 0.   , 0.   , 0.   , 0.   , 0.   , 0.625, 2.125,\n",
    "             0.   , 0.   , 3.75 , 0.   , 0.   , 0.625, 2.625, 2.   ,\n",
    "             0.   , 0.   , 1.   , 0.   , 0.75 , 1.25 , 0.   , 1.375],\n",
    "            [1.125, 0.   , 0.   , 0.5  , 0.   , 0.   , 0.625, 0.   ,\n",
    "             0.   , 0.25 , 0.875, 0.   , 0.   , 0.625, 0.75 , 0.   ,\n",
    "             0.   , 0.25 , 0.375, 0.   , 0.5  , 0.625, 0.   , 0.   ],\n",
    "            [1.375, 0.   , 0.   , 0.   , 0.   , 0.   , 0.5  , 0.   ,\n",
    "             0.   , 0.125, 1.   , 0.   , 0.   , 0.5  , 0.25 , 0.125,\n",
    "             0.   , 0.5  , 0.125, 0.125, 0.875, 0.75 , 0.   , 0.   ],\n",
    "            [5.75 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 2.875,\n",
    "             0.   , 0.   , 4.375, 0.   , 0.   , 0.5  , 2.625, 2.5  ,\n",
    "             0.   , 0.   , 1.375, 0.   , 0.875, 1.375, 0.   , 1.875],\n",
    "            [5.75 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 2.625,\n",
    "             0.   , 0.   , 4.375, 0.   , 0.   , 0.375, 2.875, 2.625,\n",
    "             0.   , 0.   , 1.625, 0.   , 0.   , 1.75 , 0.   , 2.   ],\n",
    "            [1.375, 0.   , 0.   , 0.   , 0.   , 0.   , 0.625, 0.   ,\n",
    "             0.125, 0.   , 1.5  , 0.   , 0.   , 1.   , 0.25 , 0.5  ,\n",
    "             0.   , 0.125, 0.5  , 0.   , 0.5  , 0.625, 0.   , 0.375],\n",
    "            [1.375, 0.   , 0.   , 0.   , 0.   , 0.125, 0.625, 0.   ,\n",
    "             0.   , 0.   , 1.375, 0.   , 0.   , 0.875, 0.   , 0.5  ,\n",
    "             0.   , 0.375, 0.25 , 0.   , 0.75 , 0.75 , 0.   , 0.   ],\n",
    "            [0.625, 0.   , 0.   , 0.25 , 0.   , 0.   , 0.375, 0.   ,\n",
    "             0.   , 0.375, 0.625, 0.25 , 0.   , 0.625, 0.75 , 0.   ,\n",
    "             0.   , 0.5  , 0.125, 0.25 , 0.625, 0.5  , 0.   , 0.   ],\n",
    "            [0.75 , 0.   , 0.   , 0.375, 0.25 , 0.   , 0.5  , 0.   ,\n",
    "             0.   , 0.25 , 0.5  , 0.25 , 0.   , 0.375, 0.5  , 0.   ,\n",
    "             0.   , 0.375, 0.125, 0.   , 0.375, 0.5  , 0.   , 0.   ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba246585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_pred - pynqbuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782cc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
